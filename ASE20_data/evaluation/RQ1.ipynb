{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from classifier import *\n",
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                  TC  \\\n0  org.apache.hadoop.resourceestimator.translator...   \n1  org.apache.hadoop.resourceestimator.translator...   \n2  org.apache.hadoop.resourceestimator.translator...   \n3  org.apache.hadoop.resourceestimator.translator...   \n4  org.apache.hadoop.resourceestimator.translator...   \n\n                          TM  \\\n0       testGetContainerSpec   \n1             testGetJobSize   \n2       testGetRecurrenceeId   \n3  testStringToUnixTimestamp   \n4        testResourceSkyline   \n\n                                                 CUT  \\\n0  org.apache.hadoop.resourceestimator.translator...   \n1  org.apache.hadoop.resourceestimator.translator...   \n2  org.apache.hadoop.resourceestimator.translator...   \n3  org.apache.hadoop.resourceestimator.translator...   \n4  org.apache.hadoop.resourceestimator.translator...   \n\n                                             D     L   ABS    INT    JDK  \\\n0  org.apache.hadoop.yarn.api.records.Resource  real  True  False  False   \n1  org.apache.hadoop.yarn.api.records.Resource  real  True  False  False   \n2  org.apache.hadoop.yarn.api.records.Resource  real  True  False  False   \n3  org.apache.hadoop.yarn.api.records.Resource  real  True  False  False   \n4  org.apache.hadoop.yarn.api.records.Resource  real  True  False  False   \n\n     ICB  DEP  ...  TUAPI   UINT  SYNC  CALLSITES  AFPR  RBFA  EXPCAT  \\\n0  False  0.5  ...    0.0  False   0.0        0.0   0.0   0.0     0.0   \n1  False  0.5  ...    0.0  False   0.0        0.0   0.0   0.0     0.0   \n2  False  0.5  ...    0.0  False   0.0        0.0   0.0   0.0     0.0   \n3  False  0.5  ...    0.0  False   0.0        0.0   0.0   0.0     0.0   \n4  False  0.5  ...    0.0  False   0.0        0.0   0.0   0.0     0.0   \n\n   CONDCALL    PROJ  IS_MOCK  \n0       0.0  Hadoop    False  \n1       0.0  Hadoop    False  \n2       0.0  Hadoop    False  \n3       0.0  Hadoop    False  \n4       0.0  Hadoop    False  \n\n[5 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TC</th>\n      <th>TM</th>\n      <th>CUT</th>\n      <th>D</th>\n      <th>L</th>\n      <th>ABS</th>\n      <th>INT</th>\n      <th>JDK</th>\n      <th>ICB</th>\n      <th>DEP</th>\n      <th>...</th>\n      <th>TUAPI</th>\n      <th>UINT</th>\n      <th>SYNC</th>\n      <th>CALLSITES</th>\n      <th>AFPR</th>\n      <th>RBFA</th>\n      <th>EXPCAT</th>\n      <th>CONDCALL</th>\n      <th>PROJ</th>\n      <th>IS_MOCK</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>testGetContainerSpec</td>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>org.apache.hadoop.yarn.api.records.Resource</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Hadoop</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>testGetJobSize</td>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>org.apache.hadoop.yarn.api.records.Resource</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Hadoop</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>testGetRecurrenceeId</td>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>org.apache.hadoop.yarn.api.records.Resource</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Hadoop</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>testStringToUnixTimestamp</td>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>org.apache.hadoop.yarn.api.records.Resource</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Hadoop</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>testResourceSkyline</td>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>org.apache.hadoop.yarn.api.records.Resource</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Hadoop</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = get_dataset(data_files, True).drop_duplicates(['TC','TM','D'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "543171"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df['TC'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    PRIOJ   TOTAL   MOCK\n0  Hadoop  323078  13484\n1   Flink   86141   6719\n2    Hive   23368   1490\n3   Camel   12936   1855\n4     CXF   22550   1489\n5   Druid   45332   1869\n6   HBase   11966   1072\n7   Dubbo    8623    758\n8   Oozie    5539    278\n9   Storm    3638    369",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRIOJ</th>\n      <th>TOTAL</th>\n      <th>MOCK</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hadoop</td>\n      <td>323078</td>\n      <td>13484</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Flink</td>\n      <td>86141</td>\n      <td>6719</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hive</td>\n      <td>23368</td>\n      <td>1490</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Camel</td>\n      <td>12936</td>\n      <td>1855</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CXF</td>\n      <td>22550</td>\n      <td>1489</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Druid</td>\n      <td>45332</td>\n      <td>1869</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>HBase</td>\n      <td>11966</td>\n      <td>1072</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Dubbo</td>\n      <td>8623</td>\n      <td>758</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Oozie</td>\n      <td>5539</td>\n      <td>278</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Storm</td>\n      <td>3638</td>\n      <td>369</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "pd.DataFrame([\n",
    "    {\n",
    "        'PRIOJ': p,\n",
    "        'TOTAL': df[(df['PROJ']==p)]['PROJ'].count(),\n",
    "        'MOCK': df[(df['PROJ']==p) & df['IS_MOCK']]['PROJ'].count(),\n",
    "\n",
    "    }\n",
    "    for p in projects\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'29383 mocks(5.41%)'"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "(\"%d mocks(%.2f%%)\" % (df['IS_MOCK'].sum(), df['IS_MOCK'].sum()/df['IS_MOCK'].count()*100))"
   ]
  },
  {
   "source": [
    "# MockSniffer (Intra Project Prediction)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model_core(p):\n",
    "    train = p[0]\n",
    "    test = p[1]\n",
    "    X_train = train.drop(['CUT', 'IS_MOCK', 'TC', 'TM', 'D', 'L', 'PROJ'], axis=1)\n",
    "    y_train = train['IS_MOCK']\n",
    "    X_test = test.drop(['CUT', 'IS_MOCK', 'TC', 'TM', 'D', 'L', 'PROJ'], axis=1)\n",
    "    y_test = test['IS_MOCK']\n",
    "    return run_classifier(X_train, X_test, y_train, y_test)\n",
    "\n",
    "def run_intra_project(project_data, n_folds = 10, iter_count = 100):\n",
    "    scores = []\n",
    "    pl = mp.Pool(100)\n",
    "    project_mocks = project_data[project_data['IS_MOCK']].sample(frac=1).reset_index(drop=True)\n",
    "    project_not_mocks = project_data[~project_data['IS_MOCK']]\n",
    "    fold_size = len(project_mocks)//n_folds\n",
    "    for i in range(n_folds):\n",
    "        tfidx = fold_size*i\n",
    "        mock_train = pd.concat([project_mocks.iloc[0:tfidx], project_mocks.iloc[tfidx+fold_size:]])\n",
    "        mock_test = project_mocks.iloc[tfidx:tfidx+fold_size]\n",
    "        def _gen_data():\n",
    "            train = pd.concat([\n",
    "                mock_train,\n",
    "                project_not_mocks.sample(n=fold_size*(n_folds-1))\n",
    "            ])\n",
    "            test = pd.concat([\n",
    "                mock_test,\n",
    "                project_not_mocks.sample(n=fold_size)\n",
    "            ])\n",
    "            return train, test\n",
    "        proj_score = pl.map(_model_core, [_gen_data() for n in range(iter_count)])\n",
    "        scores.extend(proj_score)\n",
    "    pl.close()\n",
    "    return {\n",
    "        k: np.mean([s[k] for s in scores])*100\n",
    "        for k in metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pool_core_bal(par):\n",
    "    project = par\n",
    "    p = df[df['PROJ'] == project]\n",
    "    return project, run_intra_project(p)\n",
    "\n",
    "runing_result =[pool_core_bal(it) for it in [*projects]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame([\n",
    "    {\n",
    "        'project': proj,\n",
    "        **perf\n",
    "    }\n",
    "    for proj, perf in runing_result\n",
    "]).set_index(['project'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          accuracy  precision     recall   f1-score\nproject                                            \nHadoop   82.899110  80.361060  87.091395  83.587826\nFlink    82.919449  81.316721  85.510432  83.345406\nHive     84.364765  84.456354  84.319463  84.331364\nCamel    79.515946  76.185840  86.123784  80.802284\nCXF      83.054392  84.668299  80.828378  82.645191\nDruid    83.411022  83.531625  83.382796  83.393547\nHBase    86.576168  84.393521  89.886916  86.997095\nDubbo    88.554667  85.753923  92.705333  89.029563\nOozie    91.142593  91.122036  91.574074  91.169781\nStorm    91.769444  87.747912  97.480556  92.265536",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n    </tr>\n    <tr>\n      <th>project</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Hadoop</th>\n      <td>82.899110</td>\n      <td>80.361060</td>\n      <td>87.091395</td>\n      <td>83.587826</td>\n    </tr>\n    <tr>\n      <th>Flink</th>\n      <td>82.919449</td>\n      <td>81.316721</td>\n      <td>85.510432</td>\n      <td>83.345406</td>\n    </tr>\n    <tr>\n      <th>Hive</th>\n      <td>84.364765</td>\n      <td>84.456354</td>\n      <td>84.319463</td>\n      <td>84.331364</td>\n    </tr>\n    <tr>\n      <th>Camel</th>\n      <td>79.515946</td>\n      <td>76.185840</td>\n      <td>86.123784</td>\n      <td>80.802284</td>\n    </tr>\n    <tr>\n      <th>CXF</th>\n      <td>83.054392</td>\n      <td>84.668299</td>\n      <td>80.828378</td>\n      <td>82.645191</td>\n    </tr>\n    <tr>\n      <th>Druid</th>\n      <td>83.411022</td>\n      <td>83.531625</td>\n      <td>83.382796</td>\n      <td>83.393547</td>\n    </tr>\n    <tr>\n      <th>HBase</th>\n      <td>86.576168</td>\n      <td>84.393521</td>\n      <td>89.886916</td>\n      <td>86.997095</td>\n    </tr>\n    <tr>\n      <th>Dubbo</th>\n      <td>88.554667</td>\n      <td>85.753923</td>\n      <td>92.705333</td>\n      <td>89.029563</td>\n    </tr>\n    <tr>\n      <th>Oozie</th>\n      <td>91.142593</td>\n      <td>91.122036</td>\n      <td>91.574074</td>\n      <td>91.169781</td>\n    </tr>\n    <tr>\n      <th>Storm</th>\n      <td>91.769444</td>\n      <td>87.747912</td>\n      <td>97.480556</td>\n      <td>92.265536</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        accuracy  precision     recall   f1-score\ncount  10.000000  10.000000  10.000000  10.000000\nmean   85.420755  83.953729  87.890313  85.756759\nstd     3.978239   4.087340   5.000845   3.891283\nmin    79.515946  76.185840  80.828378  80.802284\n25%    82.953184  81.870447  84.617205  83.357442\n50%    83.887893  84.424937  86.607589  83.959595\n75%    88.060042  85.482517  91.152285  88.521446\nmax    91.769444  91.122036  97.480556  92.265536",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>85.420755</td>\n      <td>83.953729</td>\n      <td>87.890313</td>\n      <td>85.756759</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.978239</td>\n      <td>4.087340</td>\n      <td>5.000845</td>\n      <td>3.891283</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>79.515946</td>\n      <td>76.185840</td>\n      <td>80.828378</td>\n      <td>80.802284</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>82.953184</td>\n      <td>81.870447</td>\n      <td>84.617205</td>\n      <td>83.357442</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>83.887893</td>\n      <td>84.424937</td>\n      <td>86.607589</td>\n      <td>83.959595</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>88.060042</td>\n      <td>85.482517</td>\n      <td>91.152285</td>\n      <td>88.521446</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>91.769444</td>\n      <td>91.122036</td>\n      <td>97.480556</td>\n      <td>92.265536</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "perf_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselineutil import run_baseline"
   ]
  },
  {
   "source": [
    "# Baseline 1 (Exisiting Heuristics)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          accuracy  precision     recall   f1-score\nproject                                            \nHadoop   64.457876  60.005132  86.710175  70.927235\nFlink    68.581634  62.538917  92.677482  74.682178\nHive     58.523490  58.523490  58.523490  58.523490\nCamel    64.905660  62.283430  75.579515  68.290307\nCXF      59.372733  59.475353  58.831430  59.151630\nDruid    64.499732  66.749073  57.784912  61.944365\nHBase    75.279851  68.871866  92.257463  78.867624\nDubbo    65.445910  69.073851  55.936675  61.814873\nOozie    64.235612  61.345590  76.978417  68.278294\nStorm    52.735772  53.118190  46.612466  49.652989",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n    </tr>\n    <tr>\n      <th>project</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Hadoop</th>\n      <td>64.457876</td>\n      <td>60.005132</td>\n      <td>86.710175</td>\n      <td>70.927235</td>\n    </tr>\n    <tr>\n      <th>Flink</th>\n      <td>68.581634</td>\n      <td>62.538917</td>\n      <td>92.677482</td>\n      <td>74.682178</td>\n    </tr>\n    <tr>\n      <th>Hive</th>\n      <td>58.523490</td>\n      <td>58.523490</td>\n      <td>58.523490</td>\n      <td>58.523490</td>\n    </tr>\n    <tr>\n      <th>Camel</th>\n      <td>64.905660</td>\n      <td>62.283430</td>\n      <td>75.579515</td>\n      <td>68.290307</td>\n    </tr>\n    <tr>\n      <th>CXF</th>\n      <td>59.372733</td>\n      <td>59.475353</td>\n      <td>58.831430</td>\n      <td>59.151630</td>\n    </tr>\n    <tr>\n      <th>Druid</th>\n      <td>64.499732</td>\n      <td>66.749073</td>\n      <td>57.784912</td>\n      <td>61.944365</td>\n    </tr>\n    <tr>\n      <th>HBase</th>\n      <td>75.279851</td>\n      <td>68.871866</td>\n      <td>92.257463</td>\n      <td>78.867624</td>\n    </tr>\n    <tr>\n      <th>Dubbo</th>\n      <td>65.445910</td>\n      <td>69.073851</td>\n      <td>55.936675</td>\n      <td>61.814873</td>\n    </tr>\n    <tr>\n      <th>Oozie</th>\n      <td>64.235612</td>\n      <td>61.345590</td>\n      <td>76.978417</td>\n      <td>68.278294</td>\n    </tr>\n    <tr>\n      <th>Storm</th>\n      <td>52.735772</td>\n      <td>53.118190</td>\n      <td>46.612466</td>\n      <td>49.652989</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from baselines.b1 import baseline1\n",
    "perf_bs1 = run_baseline(df, baseline1)\n",
    "perf_bs1"
   ]
  },
  {
   "source": [
    "# Baseline 2 (EvoSuite Mock List)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          accuracy  precision    recall  f1-score\nproject                                          \nHadoop   48.713290  13.929314  0.496885  0.959542\nFlink    48.898199   8.886022  0.238131  0.463831\nHive     49.899329  47.058824  1.610738  3.114860\nCamel    48.517520   6.349206  0.215633  0.417101\nCXF      48.824715  15.686275  0.537273  1.038961\nDruid    49.063670   2.702703  0.053505  0.104932\nHBase    49.300373  20.000000  0.466418  0.911577\nDubbo    49.139182  23.960000  0.791557  1.532470\nOozie    46.582734   0.000000  0.000000  0.000000\nStorm    49.322493   0.000000  0.000000  0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n    </tr>\n    <tr>\n      <th>project</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Hadoop</th>\n      <td>48.713290</td>\n      <td>13.929314</td>\n      <td>0.496885</td>\n      <td>0.959542</td>\n    </tr>\n    <tr>\n      <th>Flink</th>\n      <td>48.898199</td>\n      <td>8.886022</td>\n      <td>0.238131</td>\n      <td>0.463831</td>\n    </tr>\n    <tr>\n      <th>Hive</th>\n      <td>49.899329</td>\n      <td>47.058824</td>\n      <td>1.610738</td>\n      <td>3.114860</td>\n    </tr>\n    <tr>\n      <th>Camel</th>\n      <td>48.517520</td>\n      <td>6.349206</td>\n      <td>0.215633</td>\n      <td>0.417101</td>\n    </tr>\n    <tr>\n      <th>CXF</th>\n      <td>48.824715</td>\n      <td>15.686275</td>\n      <td>0.537273</td>\n      <td>1.038961</td>\n    </tr>\n    <tr>\n      <th>Druid</th>\n      <td>49.063670</td>\n      <td>2.702703</td>\n      <td>0.053505</td>\n      <td>0.104932</td>\n    </tr>\n    <tr>\n      <th>HBase</th>\n      <td>49.300373</td>\n      <td>20.000000</td>\n      <td>0.466418</td>\n      <td>0.911577</td>\n    </tr>\n    <tr>\n      <th>Dubbo</th>\n      <td>49.139182</td>\n      <td>23.960000</td>\n      <td>0.791557</td>\n      <td>1.532470</td>\n    </tr>\n    <tr>\n      <th>Oozie</th>\n      <td>46.582734</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Storm</th>\n      <td>49.322493</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from baselines.b2 import baseline2\n",
    "perf_bs2 = run_baseline(df, baseline2)\n",
    "perf_bs2"
   ]
  },
  {
   "source": [
    "# Baseline 3 (Empirical Rules)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          accuracy  precision     recall   f1-score\nproject                                            \nHadoop   63.297241  57.856454  97.923465  72.737289\nFlink    54.643548  52.463677  98.883762  68.554919\nHive     63.936577  58.818885  92.953020  72.047468\nCamel    53.396226  51.800000  97.735849  67.712418\nCXF      54.734721  52.598599  95.836132  67.920038\nDruid    52.701980  51.499851  92.776886  66.233766\nHBase    54.610075  52.467445  98.027052  68.351049\nDubbo    54.547493  52.492309  95.778364  67.816881\nOozie    52.338129  51.403888  85.611511  64.237517\nStorm    52.834688  51.577560  92.682927  66.273971",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n    </tr>\n    <tr>\n      <th>project</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Hadoop</th>\n      <td>63.297241</td>\n      <td>57.856454</td>\n      <td>97.923465</td>\n      <td>72.737289</td>\n    </tr>\n    <tr>\n      <th>Flink</th>\n      <td>54.643548</td>\n      <td>52.463677</td>\n      <td>98.883762</td>\n      <td>68.554919</td>\n    </tr>\n    <tr>\n      <th>Hive</th>\n      <td>63.936577</td>\n      <td>58.818885</td>\n      <td>92.953020</td>\n      <td>72.047468</td>\n    </tr>\n    <tr>\n      <th>Camel</th>\n      <td>53.396226</td>\n      <td>51.800000</td>\n      <td>97.735849</td>\n      <td>67.712418</td>\n    </tr>\n    <tr>\n      <th>CXF</th>\n      <td>54.734721</td>\n      <td>52.598599</td>\n      <td>95.836132</td>\n      <td>67.920038</td>\n    </tr>\n    <tr>\n      <th>Druid</th>\n      <td>52.701980</td>\n      <td>51.499851</td>\n      <td>92.776886</td>\n      <td>66.233766</td>\n    </tr>\n    <tr>\n      <th>HBase</th>\n      <td>54.610075</td>\n      <td>52.467445</td>\n      <td>98.027052</td>\n      <td>68.351049</td>\n    </tr>\n    <tr>\n      <th>Dubbo</th>\n      <td>54.547493</td>\n      <td>52.492309</td>\n      <td>95.778364</td>\n      <td>67.816881</td>\n    </tr>\n    <tr>\n      <th>Oozie</th>\n      <td>52.338129</td>\n      <td>51.403888</td>\n      <td>85.611511</td>\n      <td>64.237517</td>\n    </tr>\n    <tr>\n      <th>Storm</th>\n      <td>52.834688</td>\n      <td>51.577560</td>\n      <td>92.682927</td>\n      <td>66.273971</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from baselines.b3 import baseline3\n",
    "perf_bs3 = run_baseline(df, baseline3, transform_whole_dataset=True)\n",
    "perf_bs3"
   ]
  },
  {
   "source": [
    "# Compare"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         accuracy_ms  accuracy_bs1  accuracy_bs2  accuracy_bs3  precision_ms  \\\nproject                                                                        \nHadoop         82.90         64.46         48.71         63.30         80.36   \nFlink          82.92         68.58         48.90         54.64         81.32   \nHive           84.36         58.52         49.90         63.94         84.46   \nCamel          79.52         64.91         48.52         53.40         76.19   \nCXF            83.05         59.37         48.82         54.73         84.67   \nDruid          83.41         64.50         49.06         52.70         83.53   \nHBase          86.58         75.28         49.30         54.61         84.39   \nDubbo          88.55         65.45         49.14         54.55         85.75   \nOozie          91.14         64.24         46.58         52.34         91.12   \nStorm          91.77         52.74         49.32         52.83         87.75   \n\n         precision_bs1  precision_bs2  precision_bs3  recall_ms  recall_bs1  \\\nproject                                                                       \nHadoop           60.01          13.93          57.86      87.09       86.71   \nFlink            62.54           8.89          52.46      85.51       92.68   \nHive             58.52          47.06          58.82      84.32       58.52   \nCamel            62.28           6.35          51.80      86.12       75.58   \nCXF              59.48          15.69          52.60      80.83       58.83   \nDruid            66.75           2.70          51.50      83.38       57.78   \nHBase            68.87          20.00          52.47      89.89       92.26   \nDubbo            69.07          23.96          52.49      92.71       55.94   \nOozie            61.35           0.00          51.40      91.57       76.98   \nStorm            53.12           0.00          51.58      97.48       46.61   \n\n         recall_bs2  recall_bs3  f1-score_ms  f1-score_bs1  f1-score_bs2  \\\nproject                                                                    \nHadoop         0.50       97.92        83.59         70.93          0.96   \nFlink          0.24       98.88        83.35         74.68          0.46   \nHive           1.61       92.95        84.33         58.52          3.11   \nCamel          0.22       97.74        80.80         68.29          0.42   \nCXF            0.54       95.84        82.65         59.15          1.04   \nDruid          0.05       92.78        83.39         61.94          0.10   \nHBase          0.47       98.03        87.00         78.87          0.91   \nDubbo          0.79       95.78        89.03         61.81          1.53   \nOozie          0.00       85.61        91.17         68.28          0.00   \nStorm          0.00       92.68        92.27         49.65          0.00   \n\n         f1-score_bs3  \nproject                \nHadoop          72.74  \nFlink           68.55  \nHive            72.05  \nCamel           67.71  \nCXF             67.92  \nDruid           66.23  \nHBase           68.35  \nDubbo           67.82  \nOozie           64.24  \nStorm           66.27  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy_ms</th>\n      <th>accuracy_bs1</th>\n      <th>accuracy_bs2</th>\n      <th>accuracy_bs3</th>\n      <th>precision_ms</th>\n      <th>precision_bs1</th>\n      <th>precision_bs2</th>\n      <th>precision_bs3</th>\n      <th>recall_ms</th>\n      <th>recall_bs1</th>\n      <th>recall_bs2</th>\n      <th>recall_bs3</th>\n      <th>f1-score_ms</th>\n      <th>f1-score_bs1</th>\n      <th>f1-score_bs2</th>\n      <th>f1-score_bs3</th>\n    </tr>\n    <tr>\n      <th>project</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Hadoop</th>\n      <td>82.90</td>\n      <td>64.46</td>\n      <td>48.71</td>\n      <td>63.30</td>\n      <td>80.36</td>\n      <td>60.01</td>\n      <td>13.93</td>\n      <td>57.86</td>\n      <td>87.09</td>\n      <td>86.71</td>\n      <td>0.50</td>\n      <td>97.92</td>\n      <td>83.59</td>\n      <td>70.93</td>\n      <td>0.96</td>\n      <td>72.74</td>\n    </tr>\n    <tr>\n      <th>Flink</th>\n      <td>82.92</td>\n      <td>68.58</td>\n      <td>48.90</td>\n      <td>54.64</td>\n      <td>81.32</td>\n      <td>62.54</td>\n      <td>8.89</td>\n      <td>52.46</td>\n      <td>85.51</td>\n      <td>92.68</td>\n      <td>0.24</td>\n      <td>98.88</td>\n      <td>83.35</td>\n      <td>74.68</td>\n      <td>0.46</td>\n      <td>68.55</td>\n    </tr>\n    <tr>\n      <th>Hive</th>\n      <td>84.36</td>\n      <td>58.52</td>\n      <td>49.90</td>\n      <td>63.94</td>\n      <td>84.46</td>\n      <td>58.52</td>\n      <td>47.06</td>\n      <td>58.82</td>\n      <td>84.32</td>\n      <td>58.52</td>\n      <td>1.61</td>\n      <td>92.95</td>\n      <td>84.33</td>\n      <td>58.52</td>\n      <td>3.11</td>\n      <td>72.05</td>\n    </tr>\n    <tr>\n      <th>Camel</th>\n      <td>79.52</td>\n      <td>64.91</td>\n      <td>48.52</td>\n      <td>53.40</td>\n      <td>76.19</td>\n      <td>62.28</td>\n      <td>6.35</td>\n      <td>51.80</td>\n      <td>86.12</td>\n      <td>75.58</td>\n      <td>0.22</td>\n      <td>97.74</td>\n      <td>80.80</td>\n      <td>68.29</td>\n      <td>0.42</td>\n      <td>67.71</td>\n    </tr>\n    <tr>\n      <th>CXF</th>\n      <td>83.05</td>\n      <td>59.37</td>\n      <td>48.82</td>\n      <td>54.73</td>\n      <td>84.67</td>\n      <td>59.48</td>\n      <td>15.69</td>\n      <td>52.60</td>\n      <td>80.83</td>\n      <td>58.83</td>\n      <td>0.54</td>\n      <td>95.84</td>\n      <td>82.65</td>\n      <td>59.15</td>\n      <td>1.04</td>\n      <td>67.92</td>\n    </tr>\n    <tr>\n      <th>Druid</th>\n      <td>83.41</td>\n      <td>64.50</td>\n      <td>49.06</td>\n      <td>52.70</td>\n      <td>83.53</td>\n      <td>66.75</td>\n      <td>2.70</td>\n      <td>51.50</td>\n      <td>83.38</td>\n      <td>57.78</td>\n      <td>0.05</td>\n      <td>92.78</td>\n      <td>83.39</td>\n      <td>61.94</td>\n      <td>0.10</td>\n      <td>66.23</td>\n    </tr>\n    <tr>\n      <th>HBase</th>\n      <td>86.58</td>\n      <td>75.28</td>\n      <td>49.30</td>\n      <td>54.61</td>\n      <td>84.39</td>\n      <td>68.87</td>\n      <td>20.00</td>\n      <td>52.47</td>\n      <td>89.89</td>\n      <td>92.26</td>\n      <td>0.47</td>\n      <td>98.03</td>\n      <td>87.00</td>\n      <td>78.87</td>\n      <td>0.91</td>\n      <td>68.35</td>\n    </tr>\n    <tr>\n      <th>Dubbo</th>\n      <td>88.55</td>\n      <td>65.45</td>\n      <td>49.14</td>\n      <td>54.55</td>\n      <td>85.75</td>\n      <td>69.07</td>\n      <td>23.96</td>\n      <td>52.49</td>\n      <td>92.71</td>\n      <td>55.94</td>\n      <td>0.79</td>\n      <td>95.78</td>\n      <td>89.03</td>\n      <td>61.81</td>\n      <td>1.53</td>\n      <td>67.82</td>\n    </tr>\n    <tr>\n      <th>Oozie</th>\n      <td>91.14</td>\n      <td>64.24</td>\n      <td>46.58</td>\n      <td>52.34</td>\n      <td>91.12</td>\n      <td>61.35</td>\n      <td>0.00</td>\n      <td>51.40</td>\n      <td>91.57</td>\n      <td>76.98</td>\n      <td>0.00</td>\n      <td>85.61</td>\n      <td>91.17</td>\n      <td>68.28</td>\n      <td>0.00</td>\n      <td>64.24</td>\n    </tr>\n    <tr>\n      <th>Storm</th>\n      <td>91.77</td>\n      <td>52.74</td>\n      <td>49.32</td>\n      <td>52.83</td>\n      <td>87.75</td>\n      <td>53.12</td>\n      <td>0.00</td>\n      <td>51.58</td>\n      <td>97.48</td>\n      <td>46.61</td>\n      <td>0.00</td>\n      <td>92.68</td>\n      <td>92.27</td>\n      <td>49.65</td>\n      <td>0.00</td>\n      <td>66.27</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "comp_df = perf_df.rename(columns = {m: f\"{m}_ms\" for m in metrics }).join([\n",
    "    perf_bs1.rename(columns = {m: f\"{m}_bs1\" for m in metrics }),\n",
    "    perf_bs2.rename(columns = {m: f\"{m}_bs2\" for m in metrics }),\n",
    "    perf_bs3.rename(columns = {m: f\"{m}_bs3\" for m in metrics })\n",
    "]).round(2)[[ f\"{m}_{c}\" for m in metrics for c in [\"ms\", \"bs1\", \"bs2\", \"bs3\" ]]]\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\\begin{tabular}{lrrrrrrrrrrrrrrrr}\n\\toprule\n{} &  accuracy\\_ms &  accuracy\\_bs1 &  accuracy\\_bs2 &  accuracy\\_bs3 &  precision\\_ms &  precision\\_bs1 &  precision\\_bs2 &  precision\\_bs3 &  recall\\_ms &  recall\\_bs1 &  recall\\_bs2 &  recall\\_bs3 &  f1-score\\_ms &  f1-score\\_bs1 &  f1-score\\_bs2 &  f1-score\\_bs3 \\\\\nproject &              &               &               &               &               &                &                &                &            &             &             &             &              &               &               &               \\\\\n\\midrule\nHadoop  &        82.90 &         64.46 &         48.71 &         63.30 &         80.36 &          60.01 &          13.93 &          57.86 &      87.09 &       86.71 &        0.50 &       97.92 &        83.59 &         70.93 &          0.96 &         72.74 \\\\\nFlink   &        82.92 &         68.58 &         48.90 &         54.64 &         81.32 &          62.54 &           8.89 &          52.46 &      85.51 &       92.68 &        0.24 &       98.88 &        83.35 &         74.68 &          0.46 &         68.55 \\\\\nHive    &        84.36 &         58.52 &         49.90 &         63.94 &         84.46 &          58.52 &          47.06 &          58.82 &      84.32 &       58.52 &        1.61 &       92.95 &        84.33 &         58.52 &          3.11 &         72.05 \\\\\nCamel   &        79.52 &         64.91 &         48.52 &         53.40 &         76.19 &          62.28 &           6.35 &          51.80 &      86.12 &       75.58 &        0.22 &       97.74 &        80.80 &         68.29 &          0.42 &         67.71 \\\\\nCXF     &        83.05 &         59.37 &         48.82 &         54.73 &         84.67 &          59.48 &          15.69 &          52.60 &      80.83 &       58.83 &        0.54 &       95.84 &        82.65 &         59.15 &          1.04 &         67.92 \\\\\nDruid   &        83.41 &         64.50 &         49.06 &         52.70 &         83.53 &          66.75 &           2.70 &          51.50 &      83.38 &       57.78 &        0.05 &       92.78 &        83.39 &         61.94 &          0.10 &         66.23 \\\\\nHBase   &        86.58 &         75.28 &         49.30 &         54.61 &         84.39 &          68.87 &          20.00 &          52.47 &      89.89 &       92.26 &        0.47 &       98.03 &        87.00 &         78.87 &          0.91 &         68.35 \\\\\nDubbo   &        88.55 &         65.45 &         49.14 &         54.55 &         85.75 &          69.07 &          23.96 &          52.49 &      92.71 &       55.94 &        0.79 &       95.78 &        89.03 &         61.81 &          1.53 &         67.82 \\\\\nOozie   &        91.14 &         64.24 &         46.58 &         52.34 &         91.12 &          61.35 &           0.00 &          51.40 &      91.57 &       76.98 &        0.00 &       85.61 &        91.17 &         68.28 &          0.00 &         64.24 \\\\\nStorm   &        91.77 &         52.74 &         49.32 &         52.83 &         87.75 &          53.12 &           0.00 &          51.58 &      97.48 &       46.61 &        0.00 &       92.68 &        92.27 &         49.65 &          0.00 &         66.27 \\\\\n\\bottomrule\n\\end{tabular}\n\n"
    }
   ],
   "source": [
    "print(comp_df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\\begin{tabular}{lrrrrrrrrrrrrrrrr}\n\\toprule\n{} &  accuracy\\_ms &  accuracy\\_bs1 &  accuracy\\_bs2 &  accuracy\\_bs3 &  precision\\_ms &  precision\\_bs1 &  precision\\_bs2 &  precision\\_bs3 &  recall\\_ms &  recall\\_bs1 &  recall\\_bs2 &  recall\\_bs3 &  f1-score\\_ms &  f1-score\\_bs1 &  f1-score\\_bs2 &  f1-score\\_bs3 \\\\\n\\midrule\ncount &        10.00 &         10.00 &         10.00 &         10.00 &         10.00 &          10.00 &          10.00 &          10.00 &      10.00 &       10.00 &       10.00 &       10.00 &        10.00 &         10.00 &         10.00 &         10.00 \\\\\nmean  &        85.42 &         63.81 &         48.82 &         55.70 &         83.95 &          62.20 &          13.86 &          53.30 &      87.89 &       70.19 &        0.44 &       94.82 &        85.76 &         65.21 &          0.85 &         68.19 \\\\\nstd   &         3.98 &          6.05 &          0.88 &          4.27 &          4.09 &           4.96 &          14.28 &           2.71 &       5.00 &       16.73 &        0.49 &        4.00 &         3.89 &          8.65 &          0.94 &          2.57 \\\\\nmin   &        79.52 &         52.74 &         46.58 &         52.34 &         76.19 &          53.12 &           0.00 &          51.40 &      80.83 &       46.61 &        0.00 &       85.61 &        80.80 &         49.65 &          0.00 &         64.24 \\\\\n25\\%   &        82.95 &         60.59 &         48.74 &         52.97 &         81.87 &          59.61 &           3.61 &          51.64 &      84.62 &       57.96 &        0.09 &       92.82 &        83.36 &         59.82 &          0.18 &         66.63 \\\\\n50\\%   &        83.88 &         64.48 &         48.98 &         54.58 &         84.42 &          61.82 &          11.41 &          52.46 &      86.60 &       67.20 &        0.36 &       95.81 &        83.96 &         65.11 &          0.68 &         67.87 \\\\\n75\\%   &        88.06 &         65.32 &         49.26 &         54.71 &         85.48 &          65.70 &          18.92 &          52.57 &      91.15 &       84.28 &        0.53 &       97.88 &        88.52 &         70.27 &          1.02 &         68.50 \\\\\nmax   &        91.77 &         75.28 &         49.90 &         63.94 &         91.12 &          69.07 &          47.06 &          58.82 &      97.48 &       92.68 &        1.61 &       98.88 &        92.27 &         78.87 &          3.11 &         72.74 \\\\\n\\bottomrule\n\\end{tabular}\n\n"
    }
   ],
   "source": [
    "print(comp_df.describe().round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ds': conda)",
   "language": "python",
   "name": "python_defaultSpec_1598173333183"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}