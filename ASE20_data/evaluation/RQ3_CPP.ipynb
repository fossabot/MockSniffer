{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from classifier import *\n",
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                  TC  \\\n0  org.apache.hadoop.resourceestimator.translator...   \n1  org.apache.hadoop.resourceestimator.translator...   \n2  org.apache.hadoop.resourceestimator.translator...   \n3  org.apache.hadoop.resourceestimator.translator...   \n4  org.apache.hadoop.resourceestimator.translator...   \n\n                          TM  \\\n0       testGetContainerSpec   \n1             testGetJobSize   \n2       testGetRecurrenceeId   \n3  testStringToUnixTimestamp   \n4        testResourceSkyline   \n\n                                                 CUT  \\\n0  org.apache.hadoop.resourceestimator.translator...   \n1  org.apache.hadoop.resourceestimator.translator...   \n2  org.apache.hadoop.resourceestimator.translator...   \n3  org.apache.hadoop.resourceestimator.translator...   \n4  org.apache.hadoop.resourceestimator.translator...   \n\n                                             D     L   ABS    INT    JDK  \\\n0  org.apache.hadoop.yarn.api.records.Resource  real  True  False  False   \n1  org.apache.hadoop.yarn.api.records.Resource  real  True  False  False   \n2  org.apache.hadoop.yarn.api.records.Resource  real  True  False  False   \n3  org.apache.hadoop.yarn.api.records.Resource  real  True  False  False   \n4  org.apache.hadoop.yarn.api.records.Resource  real  True  False  False   \n\n     ICB  DEP  ...  TUAPI   UINT  SYNC  CALLSITES  AFPR  RBFA  EXPCAT  \\\n0  False  0.5  ...    0.0  False   0.0        0.0   0.0   0.0     0.0   \n1  False  0.5  ...    0.0  False   0.0        0.0   0.0   0.0     0.0   \n2  False  0.5  ...    0.0  False   0.0        0.0   0.0   0.0     0.0   \n3  False  0.5  ...    0.0  False   0.0        0.0   0.0   0.0     0.0   \n4  False  0.5  ...    0.0  False   0.0        0.0   0.0   0.0     0.0   \n\n   CONDCALL    PROJ  IS_MOCK  \n0       0.0  Hadoop    False  \n1       0.0  Hadoop    False  \n2       0.0  Hadoop    False  \n3       0.0  Hadoop    False  \n4       0.0  Hadoop    False  \n\n[5 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TC</th>\n      <th>TM</th>\n      <th>CUT</th>\n      <th>D</th>\n      <th>L</th>\n      <th>ABS</th>\n      <th>INT</th>\n      <th>JDK</th>\n      <th>ICB</th>\n      <th>DEP</th>\n      <th>...</th>\n      <th>TUAPI</th>\n      <th>UINT</th>\n      <th>SYNC</th>\n      <th>CALLSITES</th>\n      <th>AFPR</th>\n      <th>RBFA</th>\n      <th>EXPCAT</th>\n      <th>CONDCALL</th>\n      <th>PROJ</th>\n      <th>IS_MOCK</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>testGetContainerSpec</td>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>org.apache.hadoop.yarn.api.records.Resource</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Hadoop</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>testGetJobSize</td>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>org.apache.hadoop.yarn.api.records.Resource</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Hadoop</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>testGetRecurrenceeId</td>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>org.apache.hadoop.yarn.api.records.Resource</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Hadoop</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>testStringToUnixTimestamp</td>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>org.apache.hadoop.yarn.api.records.Resource</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Hadoop</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>testResourceSkyline</td>\n      <td>org.apache.hadoop.resourceestimator.translator...</td>\n      <td>org.apache.hadoop.yarn.api.records.Resource</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Hadoop</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df = get_dataset(data_files, True).drop_duplicates(['TC','TM','D'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "543171"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df['TC'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    PRIOJ   TOTAL   MOCK\n0  Hadoop  323078  13484\n1   Flink   86141   6719\n2    Hive   23368   1490\n3   Camel   12936   1855\n4     CXF   22550   1489\n5   Druid   45332   1869\n6   HBase   11966   1072\n7   Dubbo    8623    758\n8   Oozie    5539    278\n9   Storm    3638    369",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRIOJ</th>\n      <th>TOTAL</th>\n      <th>MOCK</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hadoop</td>\n      <td>323078</td>\n      <td>13484</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Flink</td>\n      <td>86141</td>\n      <td>6719</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hive</td>\n      <td>23368</td>\n      <td>1490</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Camel</td>\n      <td>12936</td>\n      <td>1855</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CXF</td>\n      <td>22550</td>\n      <td>1489</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Druid</td>\n      <td>45332</td>\n      <td>1869</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>HBase</td>\n      <td>11966</td>\n      <td>1072</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Dubbo</td>\n      <td>8623</td>\n      <td>758</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Oozie</td>\n      <td>5539</td>\n      <td>278</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Storm</td>\n      <td>3638</td>\n      <td>369</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "pd.DataFrame([\n",
    "    {\n",
    "        'PRIOJ': p,\n",
    "        'TOTAL': df[(df['PROJ']==p)]['PROJ'].count(),\n",
    "        'MOCK': df[(df['PROJ']==p) & df['IS_MOCK']]['PROJ'].count(),\n",
    "\n",
    "    }\n",
    "    for p in projects\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'29383 mocks(5.41%)'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "(\"%d mocks(%.2f%%)\" % (df['IS_MOCK'].sum(), df['IS_MOCK'].sum()/df['IS_MOCK'].count()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df.copy()"
   ]
  },
  {
   "source": [
    "# Cross Project Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_core(par):\n",
    "    from sklearn.feature_selection import SelectKBest, chi2\n",
    "    p9 = par[0]\n",
    "    p1 = par[1]\n",
    "    train = balance_dataset(p9)\n",
    "    test = balance_dataset(p1)\n",
    "    X_train = train.drop(['CUT', 'IS_MOCK', 'TC', 'TM', 'D', 'L', 'PROJ'], axis=1)\n",
    "    y_train = train['IS_MOCK']\n",
    "    # feature_selection = SelectKBest(score_func=chi2, k=12)\n",
    "    # X_train = feature_selection.fit_transform(X_train, y_train)\n",
    "    X_test = test.drop(['CUT', 'IS_MOCK', 'TC', 'TM', 'D', 'L', 'PROJ'], axis=1)\n",
    "    y_test = test['IS_MOCK']\n",
    "    # X_test = feature_selection.transform(X_test)\n",
    "    return run_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl = mp.Pool()\n",
    "\n",
    "def pool_core_bal(par):\n",
    "    iter_count = 100\n",
    "    project = par\n",
    "    p9 = training_data[training_data['PROJ'] != project]\n",
    "    p1 = training_data[training_data['PROJ'] == project]\n",
    "    scores = pl.map_async(_run_core, ((p9, p1) for i in range(iter_count)))\n",
    "    return project, scores\n",
    "\n",
    "runing_result = [pool_core_bal(p) for p in projects]\n",
    "runing_result = [\n",
    "    (p,{\n",
    "        k: np.mean([s[k] for s in r.get()])*100\n",
    "        for k in metrics\n",
    "    })\n",
    "    for p,r in runing_result\n",
    "]\n",
    "pl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame([\n",
    "    {\n",
    "        'project': proj,\n",
    "        **perf\n",
    "    }\n",
    "    for proj, perf in runing_result\n",
    "]).set_index(['project'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          accuracy  precision     recall   f1-score\nproject                                            \nHadoop   75.081578  73.060139  79.464551  76.127886\nFlink    75.388302  69.758053  89.636553  78.457752\nHive     65.903356  74.602175  48.212081  58.570688\nCamel    67.110512  66.506446  68.944474  67.697884\nCXF      71.555406  73.457337  67.546004  70.365373\nDruid    66.503210  68.374688  61.426431  64.706740\nHBase    76.419310  75.002291  79.262127  77.072561\nDubbo    66.678760  72.217085  54.323219  61.991363\nOozie    73.922662  80.716945  62.931655  70.676111\nStorm    71.155827  72.857790  67.479675  70.060175",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n    </tr>\n    <tr>\n      <th>project</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Hadoop</th>\n      <td>75.081578</td>\n      <td>73.060139</td>\n      <td>79.464551</td>\n      <td>76.127886</td>\n    </tr>\n    <tr>\n      <th>Flink</th>\n      <td>75.388302</td>\n      <td>69.758053</td>\n      <td>89.636553</td>\n      <td>78.457752</td>\n    </tr>\n    <tr>\n      <th>Hive</th>\n      <td>65.903356</td>\n      <td>74.602175</td>\n      <td>48.212081</td>\n      <td>58.570688</td>\n    </tr>\n    <tr>\n      <th>Camel</th>\n      <td>67.110512</td>\n      <td>66.506446</td>\n      <td>68.944474</td>\n      <td>67.697884</td>\n    </tr>\n    <tr>\n      <th>CXF</th>\n      <td>71.555406</td>\n      <td>73.457337</td>\n      <td>67.546004</td>\n      <td>70.365373</td>\n    </tr>\n    <tr>\n      <th>Druid</th>\n      <td>66.503210</td>\n      <td>68.374688</td>\n      <td>61.426431</td>\n      <td>64.706740</td>\n    </tr>\n    <tr>\n      <th>HBase</th>\n      <td>76.419310</td>\n      <td>75.002291</td>\n      <td>79.262127</td>\n      <td>77.072561</td>\n    </tr>\n    <tr>\n      <th>Dubbo</th>\n      <td>66.678760</td>\n      <td>72.217085</td>\n      <td>54.323219</td>\n      <td>61.991363</td>\n    </tr>\n    <tr>\n      <th>Oozie</th>\n      <td>73.922662</td>\n      <td>80.716945</td>\n      <td>62.931655</td>\n      <td>70.676111</td>\n    </tr>\n    <tr>\n      <th>Storm</th>\n      <td>71.155827</td>\n      <td>72.857790</td>\n      <td>67.479675</td>\n      <td>70.060175</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_plot = [\n",
    "    {\n",
    "        'project': p,\n",
    "        'metric': m,\n",
    "        'value': perf_df.at[p, m],\n",
    "    }\n",
    "    for p in projects\n",
    "    for m in metrics\n",
    "]\n",
    "perf_plot = pd.DataFrame(perf_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        accuracy  precision     recall   f1-score\ncount  10.000000  10.000000  10.000000  10.000000\nmean   70.971892  72.655295  67.922677  69.572653\nstd     4.138576   3.942011  12.361396   6.548617\nmin    65.903356  66.506446  48.212081  58.570688\n25%    66.786698  70.372811  61.802737  65.454526\n50%    71.355616  72.958964  67.512839  70.212774\n75%    74.791849  74.315965  76.682714  74.764942\nmax    76.419310  80.716945  89.636553  78.457752",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>70.971892</td>\n      <td>72.655295</td>\n      <td>67.922677</td>\n      <td>69.572653</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.138576</td>\n      <td>3.942011</td>\n      <td>12.361396</td>\n      <td>6.548617</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>65.903356</td>\n      <td>66.506446</td>\n      <td>48.212081</td>\n      <td>58.570688</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>66.786698</td>\n      <td>70.372811</td>\n      <td>61.802737</td>\n      <td>65.454526</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>71.355616</td>\n      <td>72.958964</td>\n      <td>67.512839</td>\n      <td>70.212774</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>74.791849</td>\n      <td>74.315965</td>\n      <td>76.682714</td>\n      <td>74.764942</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>76.419310</td>\n      <td>80.716945</td>\n      <td>89.636553</td>\n      <td>78.457752</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "perf_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\\begin{tabular}{lrrrr}\n\\toprule\n{} &  accuracy &  precision &  recall &  f1-score \\\\\nproject &           &            &         &           \\\\\n\\midrule\nHadoop  &     75.08 &      73.06 &   79.46 &     76.13 \\\\\nFlink   &     75.39 &      69.76 &   89.64 &     78.46 \\\\\nHive    &     65.90 &      74.60 &   48.21 &     58.57 \\\\\nCamel   &     67.11 &      66.51 &   68.94 &     67.70 \\\\\nCXF     &     71.56 &      73.46 &   67.55 &     70.37 \\\\\nDruid   &     66.50 &      68.37 &   61.43 &     64.71 \\\\\nHBase   &     76.42 &      75.00 &   79.26 &     77.07 \\\\\nDubbo   &     66.68 &      72.22 &   54.32 &     61.99 \\\\\nOozie   &     73.92 &      80.72 &   62.93 &     70.68 \\\\\nStorm   &     71.16 &      72.86 &   67.48 &     70.06 \\\\\n\\bottomrule\n\\end{tabular}\n\n"
    }
   ],
   "source": [
    "print(perf_df.round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}